# Knowledge Base with PDF - RAG Example

Este exemplo demonstra como usar a base de conhecimento (Knowledge Base) do Agno com:
- **Qdrant** rodando em container Docker
- **PDF grande** carregado e indexado rapidamente
- **Embeddings locais** usando Ollama (gemma:2b)
- **LLM na cloud** para geraÃ§Ã£o (kimi-k2:1t-cloud)

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Large PDF     â”‚â”€â”€â”€â”€â”€â–¶â”‚ Local Ollama     â”‚â”€â”€â”€â”€â”€â–¶â”‚ Qdrant Vector  â”‚
â”‚   Document      â”‚      â”‚ Embeddings       â”‚      â”‚ Database        â”‚
â”‚                 â”‚      â”‚ (gemma:2b)       â”‚      â”‚ (Container)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Ollama Cloud     â”‚â—€â”€â”€â”€â”€â”€â”‚ Agent with      â”‚
                         â”‚ (kimi-k2:1t)     â”‚      â”‚ RAG             â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ©-requisitos

1. **Docker** instalado e rodando
2. **Ollama local** com o modelo `gemma:2b`:
   ```bash
   ollama pull gemma:2b
   ```
3. **API Key** do Ollama Cloud:
   ```bash
   export OLLAMA_API_KEY=your-api-key
   ```
4. **PDF** no caminho especificado

## Como Funciona

### 1. InicializaÃ§Ã£o do Qdrant
```go
qdrantContainer, err := qdrantcontainer.Run(ctx, "qdrant/qdrant:v1.7.4")
```
- Inicia um container Qdrant automaticamente
- ObtÃ©m o endpoint HTTP para conexÃ£o
- Cleanup automÃ¡tico ao finalizar

### 2. Embeddings Locais
```go
localEmbedder := embedder.NewOllamaEmbedder(
    embedder.WithModel("gemma:2b"),
    embedder.WithBaseURL("http://localhost:11434"),
)
```
- Usa Ollama local para gerar embeddings
- Modelo `gemma:2b` (2048 dimensÃµes)
- **Vantagem**: Embeddings rÃ¡pidos e sem custo de API

### 3. Vector Database
```go
vectorDB := qdrant.New(
    qdrant.WithURL(qdrantHost),
    qdrant.WithCollectionName("mistral_knowledge"),
    qdrant.WithDimension(2048),
    qdrant.WithDistance("cosine"),
)
```
- Cria coleÃ§Ã£o no Qdrant
- Usa distÃ¢ncia cosine para similaridade
- DimensÃ£o 2048 (compatÃ­vel com gemma:2b)

### 4. Carregamento do PDF
```go
err = kb.LoadDocumentFromPath(ctx, pdfPath, nil)
```
- Carrega e processa o PDF automaticamente
- Divide em chunks otimizados
- **OtimizaÃ§Ã£o automÃ¡tica**:
  - PDFs pequenos (< 500 chunks): Processamento sequencial com progressbar
  - PDFs grandes (â‰¥ 500 chunks): **Processamento paralelo** com 5 workers
  - Batches de 50 documentos por vez
  - Progressbar visual mostrando: `[â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 45% (23/50 batches, 1150/2500 docs)`
- Gera embeddings para cada chunk
- Armazena no Qdrant com metadata

### 5. Agent com RAG
```go
ag, err := agent.NewAgent(agent.AgentConfig{
    Knowledge:             kb,
    AddKnowledgeToContext: true,
    KnowledgeMaxDocuments: 5,
})
```
- Agent busca documentos relevantes automaticamente
- Adiciona ao contexto da query
- LLM cloud gera resposta baseada no conhecimento

## OtimizaÃ§Ãµes para PDFs Grandes

### Processamento Paralelo
O sistema processa chunks do PDF em paralelo para velocidade mÃ¡xima.

### Batch Embeddings
Embeddings sÃ£o gerados em batches para eficiÃªncia.

### IndexaÃ§Ã£o Inteligente
Qdrant indexa os vetores automaticamente para buscas rÃ¡pidas.

## ExecuÃ§Ã£o

```bash
# Certifique-se que Docker estÃ¡ rodando
docker ps

# Certifique-se que Ollama local estÃ¡ rodando
ollama list | grep gemma:2b

# Execute o exemplo
go run main.go
```

## Output Esperado

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       Knowledge Base with PDF - RAG Example              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ³ Starting Qdrant container...
âœ… Qdrant running at: http://localhost:6333

ğŸ”¤ Initializing local Ollama embedder (gemma:2b)...
ğŸ“Š Setting up Qdrant vector database...
ğŸ“š Creating knowledge base...
ğŸ“„ Loading PDF: /path/to/pdf
â³ This may take a few minutes for large PDFs...
âœ… PDF loaded successfully in 2m30s

ğŸ¤– Creating agent with Ollama Cloud model (kimi-k2:1t-cloud)...
âœ… Agent ready!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Query 1: What is Mistral AI and what are its main features?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¤– Answer (took 3.2s):
[Resposta detalhada baseada no PDF]
```

## Perguntas Demonstradas

1. **IntroduÃ§Ã£o**: O que Ã© Mistral AI?
2. **RAG**: Como funciona RAG com Mistral?
3. **Embeddings**: Melhores prÃ¡ticas
4. **Deployment**: Deploy no AWS Bedrock
5. **Agents**: Papel dos agents no sistema

## Vantagens desta Arquitetura

âœ… **Custo Reduzido**: Embeddings locais = sem custo de API  
âœ… **Performance**: Qdrant Ã© extremamente rÃ¡pido  
âœ… **Escalabilidade**: Container pode ser escalado facilmente  
âœ… **Qualidade**: Cloud LLM (kimi-k2:1t) para respostas de alta qualidade  
âœ… **Flexibilidade**: Troque componentes facilmente  

## Troubleshooting

### Erro: "Docker nÃ£o estÃ¡ rodando"
```bash
# Linux
sudo systemctl start docker

# macOS
open -a Docker
```

### Erro: "Modelo gemma:2b nÃ£o encontrado"
```bash
ollama pull gemma:2b
```

### PDF muito grande
Ajuste o chunk size no cÃ³digo se necessÃ¡rio:
```go
// Em knowledge.LoadPDF
chunkSize := 1000  // caracteres por chunk
```

## PrÃ³ximos Passos

- Experimentar com outros modelos de embedding
- Adicionar filtros de metadata para buscas especÃ­ficas
- Implementar cache de embeddings
- Testar com outros formatos (Markdown, HTML, etc.)
